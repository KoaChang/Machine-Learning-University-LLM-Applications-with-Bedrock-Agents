{"page_content": "COST09-BP03 Supply resources dynamically - Cost Optimization PillarCOST09-BP03 Supply resources dynamically - Cost Optimization PillarAWSDocumentationAWS Well-ArchitectedAWS Well-Architected FrameworkImplementation guidanceImplementation stepsResourcesCOST09-BP03 Supply resources dynamicallyResources are provisioned in a planned manner. This can be demand-based, such as through automatic scaling, or time-based, where demand is predictable and resources are provided based on time. These methods result in the least amount of over-provisioning or under-provisioning.\nLevel of risk exposed if this best practice\n    is not established: Low\n  \nImplementation guidance\n\n      There are several ways for AWS customers to increase the resources available to their applications and supply resources to meet the demand. One of these options is to use AWS Instance Scheduler, which automates the starting and stopping of Amazon Elastic Compute Cloud (Amazon EC2) and Amazon Relational Database Service (Amazon RDS) instances. The other option is to use AWS Auto Scaling, which allows you to automatically scale your computing resources based on the demand of your application or service. Supplying resources based on demand will allow you to pay for the resources you use only, reduce cost by launching resources when they are needed, and terminate them when they aren't.\n    \n\nAWS Instance Scheduler \n      allows you to configure the stop and start of your Amazon EC2 and Amazon RDS instances \n      at defined times so that you can meet the demand for the same resources within a consistent time \n      pattern such as every day user access Amazon EC2 instances at eight in the morning that they don\u2019t need \n      after six at night. This solution helps reduce operational cost by stopping resources that are \n      not in use and starting them when they are needed. \n    \n\n\nCost optimization with AWS Instance Scheduler.\n\n\n\nYou can also easily configure schedules for your Amazon EC2 instances across your accounts and Regions with a simple user interface (UI) using AWS Systems Manager Quick Setup. You can schedule Amazon EC2 or Amazon RDS instances with AWS Instance Scheduler and you can stop and start existing instances. However, you cannot stop and start instances which are part of your Auto Scaling group (ASG) or that manage services such as Amazon Redshift or Amazon OpenSearch Service. Auto Scaling groups have their own scheduling for the instances in the group and these instances are created. \nAWS Auto Scaling helps you adjust your capacity to maintain steady, predictable performance at the lowest possible cost to meet changing demand. It is a fully managed and free service to scale the capacity of your application that integrates with Amazon EC2 instances and Spot Fleets, Amazon ECS, Amazon DynamoDB, and Amazon Aurora. Auto Scaling provides automatic resource discovery to help find resources in your workload that can be configured, it has built-in scaling strategies to optimize performance, costs, or a balance between the two, and provides predictive scaling to assist with regularly occurring spikes. \n\n      There are multiple scaling options available to scale your Auto Scaling group:\n    \n\n\n\n          Maintain current instance levels at all times\n        \n\n\n          Scale manually\n        \n\n\n          Scale based on a schedule\n        \n\n\n          Scale based on demand\n        \n\n\n          Use predictive scaling\n        \n\n\n      Auto Scaling policies differ and can be categorized as dynamic and scheduled scaling policies. Dynamic policies are manual or dynamic scaling which, scheduled or predictive scaling. You can use scaling policies for dynamic, scheduled, and predictive scaling. You can also use metrics and alarms from Amazon CloudWatch to trigger scaling events for your workload. We recommend you use launch templates, which allow you to access the latest features and improvements. Not all Auto Scaling features are available when you use launch configurations. For example, you cannot create an Auto Scaling group that launches both Spot and On-Demand Instances or that specifies multiple instance types. You must use a launch template to configure these features. When using launch templates, we recommended you version each one. With versioning of launch templates, you can create a subset of the full set of parameters. Then, you can reuse it to create other versions of the same launch template. \n    \n\n      You can use AWS Auto Scaling or incorporate scaling in your code with AWS APIs or SDKs. This reduces your overall workload costs by removing the operational cost from manually making changes to your environment, and changes can be performed much faster. This also matches your workload resourcing to your demand at any time. In order to follow this best practice and supply resources dynamically for your organization, you should understand horizontal and vertical scaling in the AWS Cloud, as well as the nature of the applications running on Amazon EC2 instances. It is better for your Cloud Financial Management team to work with technical teams to follow this best practice. \n    \n\nElastic Load Balancing (Elastic Load Balancing) helps you scale by distributing demand across multiple resources. With using ASG and Elastic Load Balancing, you can manage incoming requests by optimally routing traffic so that no one instance is overwhelmed in an Auto Scaling group. The requests would be distributed among all the targets of a target group in a round-robin fashion without consideration for capacity or utilization.\n    \n\n      Typical metrics can be standard Amazon EC2 metrics, such as CPU utilization, network throughput, and Elastic Load Balancing observed request and response latency. When possible, you should use a metric that is indicative of customer experience, typically a custom metric that might originate from application code within your workload. To elaborate how to meet the demand dynamically in this document, we will group Auto Scaling into two categories as demand-based and time-based supply models and deep dive into each. \n    \nDemand-based supply: Take advantage of elasticity of the cloud to supply resources to meet changing demand by relying on near real-time demand state. For demand-based supply, use APIs or service features to programmatically vary the amount of cloud resources in your architecture. This allows you to scale components in your architecture and increase the number of resources during demand spikes to maintain performance and decrease capacity when demand subsides to reduce costs. \n\n\nDemand-based dynamic scaling policies\n\n \n\n\n\nSimple/Step Scaling: Monitors metrics and adds/removes instances as per steps defined by the customers manually.\n        \n\n\nTarget Tracking: Thermostat-like control mechanism that automatically adds or removes instances to maintain metrics at a customer defined target.\n        \n\nWhen architecting with a demand-based approach keep in mind two key considerations.\n      First, understand how quickly you must provision new resources. Second, understand that\n      the size of margin between supply and demand will shift. You must be ready to cope with\n      the rate of change in demand and also be ready for resource failures.\nTime-based supply: A time-based approach aligns resource\n      capacity to demand that is predictable or well-defined by time. This approach is typically not\n      dependent upon utilization levels of the resources. A time-based approach ensures that\n      resources are available at the specific time they are required and can be provided without\n      any delays due to start-up procedures and system or consistency checks. Using a time-based\n      approach, you can provide additional resources or increase capacity during busy\n      periods.\n\n\nTime-based scaling policies", "metadata": {"source": "https://docs.aws.amazon.com/wellarchitected/latest/cost-optimization-pillar/cost_manage_demand_resources_dynamic.html", "title": "COST09-BP03 Supply resources dynamically - Cost Optimization Pillar", "description": "Resources are provisioned in a planned manner. This can be demand-based, such as through automatic scaling, or time-based, where demand is predictable and resources are provided based on time. These methods result in the least amount of over-provisioning or under-provisioning.", "language": "en-US"}}