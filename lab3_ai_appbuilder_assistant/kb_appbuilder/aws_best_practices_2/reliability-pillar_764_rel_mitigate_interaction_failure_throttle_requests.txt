{"page_content": "REL05-BP02 Throttle requests - Reliability PillarREL05-BP02 Throttle requests - Reliability PillarAWSDocumentationAWS Well-ArchitectedAWS Well-Architected FrameworkImplementation guidanceImplementation stepsResourcesREL05-BP02 Throttle requestsThrottle requests to mitigate resource exhaustion due to unexpected increases in demand. Requests below throttling rates are processed while those over the defined limit are rejected with a return a message indicating the request was throttled. \nDesired outcome: Large volume spikes either from sudden customer traffic increases, flooding attacks, or retry storms are mitigated by request throttling, allowing workloads to continue normal processing of supported request volume. \n  \nCommon anti-patterns:\n\n\n\n        API endpoint throttles are not implemented or are left at default values without considering expected volumes.\n      \n\n\n        API endpoints are not load tested or throttling limits are not tested.\n      \n\n\n        Throttling request rates without considering request size or complexity.\n      \n\n\n        Testing maximum request rates or maximum request size, but not testing both together.\n      \n\n\n        Resources are not provisioned to the same limits established in testing.\n      \n\n\n        Usage plans have not been configured or considered for application to application (A2A) API consumers.\n      \n\n\n        Queue consumers that horizontally scale do not have maximum concurrency settings configured.\n      \n\n\n        Rate limiting on a per IP address basis has not been implemented.\n      \n\nBenefits of establishing this best practice: Workloads that set throttle limits are able to operate normally and process accepted request load successfully under unexpected volume spikes. Sudden or sustained spikes of requests to APIs and queues are throttled and do not exhaust request processing resources. Rate limits throttle individual requestors so that high volumes of traffic from a single IP address or API consumer will not exhaust resources impact other consumers. \n  \nLevel of risk exposed if this best practice\n    is not established: High\n  \nImplementation guidance\n\n  Services should be designed to process a known capacity of requests; this capacity can be established through load testing. If request arrival rates exceed limits, the appropriate response signals that a request has been throttled. This allows the consumer to handle the error and retry later. \n\n\n      When your service requires a throttling implementation, consider implementing the token bucket algorithm, where a token counts for a request. Tokens are refilled at a throttle rate per second and emptied asynchronously by one token per request.\n    \n\n\nThe token bucket algorithm.\n\n \n\nAmazon API Gateway implements the token bucket algorithm according to account and region limits and can be configured per-client with usage plans. Additionally, Amazon Simple Queue Service (Amazon SQS) and Amazon Kinesis can buffer requests to smooth out the request rate, and allow higher throttling rates for requests that can be addressed. Finally, you can implement rate limiting with AWS WAF to throttle specific API consumers that generate unusually high load.\n    \nImplementation steps\n\n      You can configure API Gateway with throttling limits for your APIs and return 429 Too Many Requests errors when limits are exceeded. You can use AWS WAF with your AWS AppSync and API Gateway endpoints to enable rate limiting on a per IP address basis. Additionally, where your system can tolerate asynchronous processing, you can put messages into a queue or stream to speed up responses to service clients, which allows you to burst to higher throttle rates. \n    \n\n      With asynchronous processing, when you\u00e2\u20ac\u2122ve configured Amazon SQS as an event source for AWS Lambda, you can configure maximum concurrency to avoid high event rates from consuming available account concurrent execution quota needed for other services in your workload or account.\n    \n\n      While API Gateway provides a managed implementation of the token bucket, in cases where you cannot use API Gateway, you can take advantage of language specific open-source implementations (see related examples in Resources) of the token bucket for your services. \n    \n\n\n\n          Understand and configure API Gateway throttling limits at the account level per region, API per stage, and API key per usage plan levels.\n        \n\n\n          Apply AWS WAF rate limiting rules to API Gateway and AWS AppSync endpoints to protect against floods and block malicious IPs. Rate limiting rules can also be configured on AWS AppSync API keys for A2A consumers. \n        \n\n\n          Consider whether you require more throttling control than rate limiting for AWS AppSync APIs, and if so, configure an API Gateway in front of your AWS AppSync endpoint.\n        \n\n\n          When Amazon SQS queues are set up as triggers for Lambda queue consumers, set maximum concurrency to a value that processes enough to meet your service level objectives but does not consume concurrency limits impacting other Lambda functions. Consider setting reserved concurrency on other Lambda functions in the same account and region when you consume queues with Lambda. \n        \n\n\n          Use API Gateway with native service integrations to Amazon SQS or Kinesis to buffer requests. \n        \n\n\n          If you cannot use API Gateway, look at language specific libraries to implement the token bucket algorithm for your workload. Check the examples section and do your own research to find a suitable library.\n        \n\n\n          Test limits that you plan to set, or that you plan to allow to be increased, and document the tested limits.\n        \n\n\n          Do not increase limits beyond what you establish in testing. When increasing a limit, verify that provisioned resources are already equivalent to or greater than those in test scenarios before applying the increase.\n        \n\nResources\n\nRelated best practices:\n\n\n\n\nREL04-BP03 Do constant work\n\n\n\nREL05-BP03 Control and limit retry calls\n\n\n\nRelated documents:\n\n\n\n\nAmazon API Gateway: Throttle API Requests for Better\n          Throughput\n\n\nAWS WAF: Rate-based rule statement\n        \n\n\n          Introducing maximum concurrency of AWS Lambda when using Amazon SQS as an event source\n        \n\nAWS Lambda: Maximum Concurrency\n        \n\n\nRelated examples:\n\n\n\n\n          The three most important AWS WAF rate-based rules\n        \n\n\n          Java Bucket4j\n        \n\n\n          Python token-bucket\n        \n\n \n          Node token-bucket\n        \n\n\n          .NET System Threading Rate Limiting\n        \n\n\nRelated videos:\n\n\n\n\n          Implementing GraphQL API security best practices with AWS AppSync\n\n\nRelated tools:\n\n\n\n\n          Amazon API Gateway\n        \n\nAWS AppSync\n\n \n          Amazon SQS\n        \n\n\n          Amazon Kinesis\n        \n\nAWS WAF\n\n Javascript is disabled or is unavailable in your browser.To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.Document ConventionsREL05-BP01 Implement graceful degradation to transform\n  applicable hard dependencies into soft dependenciesREL05-BP03 Control and limit retry callsDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.", "metadata": {"source": "https://docs.aws.amazon.com/wellarchitected/latest/reliability-pillar/rel_mitigate_interaction_failure_throttle_requests.html", "title": "REL05-BP02 Throttle requests - Reliability Pillar", "description": "Throttle requests to mitigate resource exhaustion due to unexpected increases in demand. Requests below throttling rates are processed while those over the defined limit are rejected with a return a message indicating the request was throttled.", "language": "en-US"}}