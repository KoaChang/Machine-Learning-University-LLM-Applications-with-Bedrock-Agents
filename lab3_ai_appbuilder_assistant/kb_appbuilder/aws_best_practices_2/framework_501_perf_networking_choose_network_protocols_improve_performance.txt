{"page_content": "PERF04-BP05 Choose network protocols to improve performance - AWS Well-Architected FrameworkPERF04-BP05 Choose network protocols to improve performance - AWS Well-Architected FrameworkAWSDocumentationAWS Well-ArchitectedFrameworkImplementation guidanceResourcesPERF04-BP05 Choose network protocols to improve\n  performance\n    Make decisions about protocols for communication between systems and\n    networks based on the impact to the workload\u2019s performance.\n  \n    There is a relationship between latency and bandwidth to achieve\n    throughput. If your file transfer is using Transmission Control\n    Protocol (TCP), higher latencies will most likely reduce overall\n    throughput. There are approaches to fix this with TCP tuning and\n    optimized transfer protocols, but one solution is to use User\n    Datagram Protocol (UDP).\n  \nCommon anti-patterns:\n\n\n\n        You use TCP for all workloads regardless of performance\n        requirements.\n      \n\nBenefits of establishing this best\n      practice: Verifying that an appropriate protocol is used for communication\n    between users and workload components helps improve overall user\n    experience for your applications. For instance, connection-less UDP\n    allows for high speed, but it doesn't offer retransmission or high\n    reliability. TCP is a full featured protocol, but it requires\n    greater overhead for processing the packets.  \n  \nLevel of risk exposed if this best practice\n    is not established: Medium\n  \nImplementation guidance\n\n      If you have the ability to choose different protocols for your\n      application and you have expertise in this area, optimize your\n      application and end-user experience by using a different protocol.\n      Note that this approach comes with significant difficulty and\n      should only be attempted if you have optimized your application in\n      other ways first.\n    \n\n      A primary consideration for improving your workload\u2019s performance\n      is to understand the latency and throughput requirements, and then\n      choose network protocols that optimize performance.\n    \n\nWhen to consider using TCP\n\n\n      TCP provides reliable data delivery, and can be used for\n      communication between workload components where reliability and\n      guaranteed delivery of data is important. Many web-based\n      applications rely on TCP-based protocols, such as HTTP and HTTPS,\n      to open TCP sockets for communication between application\n      components. Email and file data transfer are common applications\n      that also make use of TCP, as it is a simple and reliable transfer\n      mechanism between application components. Using TLS with TCP can\n      add some overhead to the communication, which can result in\n      increased latency and reduced throughput, but it comes with the\n      advantage of security. The overhead comes mainly from the added\n      overhead of the handshake process, which can take several\n      round-trips to complete. Once the handshake is complete, the\n      overhead of encrypting and decrypting data is relatively small.\n    \n\nWhen to consider using UDP\n\n\n      UDP is a connection-less-oriented protocol and is therefore\n      suitable for applications that need fast, efficient transmission,\n      such as log, monitoring, and VoIP data. Also, consider using UDP\n      if you have workload components that respond to small queries from\n      large numbers of clients to ensure optimal performance of the\n      workload. Datagram Transport Layer Security (DTLS) is the UDP\n      equivalent of Transport Layer Security (TLS). When using DTLS with\n      UDP, the overhead comes from encrypting and decrypting the data,\n      as the handshake process is simplified. DTLS also adds a small\n      amount of overhead to the UDP packets, as it includes additional\n      fields to indicate the security parameters and to detect\n      tampering.\n    \n\nWhen to consider using SRD\n\n\n      Scalable reliable datagram (SRD) is a network transport protocol\n      optimized for high-throughput workloads due to its ability to\n      load-balancer traffic across multiple paths and quickly recover\n      from packet drops or link failures. SRD is therefore best used for\n      high performance computing (HPC) workloads that require high\n      throughput and low latency communication between compute nodes.\n      This might include parallel processing tasks such as simulation,\n      modelling, and data analysis that involve a large amount of data\n      transfer between nodes.\n    \nImplementation steps\n\n\n\n            Use\n            the\u00a0AWS Global Accelerator\u00a0and\u00a0AWS Transfer Family\u00a0services to improve the throughput of\n            your online file transfer applications. The AWS Global Accelerator service helps you achieve lower latency between\n            your client devices and your workload on AWS. With AWS Transfer Family, you can use TCP-based protocols such as\n            Secure Shell File Transfer Protocol (SFTP) and File Transfer\n            Protocol over SSL (FTPS) to securely scale and manage your\n            file transfers to AWS storage services.\n          \n\n\n            Use network latency to determine if TCP is appropriate for\n            communication between workload components. If the network\n            latency between your client application and server is high,\n            then the TCP three-way handshake can take some time, thereby\n            impacting on the responsiveness of your application. Metrics\n            such as time to first byte (TTFB) and round-trip time (RTT)\n            can be used to measure network latency. If your workload\n            serves dynamic content to users, consider\n            using\u00a0Amazon CloudFront, which establishes a persistent connection\n            to each origin for dynamic content to remove the connection\n            setup time that would otherwise slow down each client\n            request.\n          \n\n\n            Using TLS with TCP or UDP can result in increased latency\n            and reduced throughput for your workload due to the impact\n            of encryption and decryption. For such workloads, consider\n            SSL/TLS offloading\n            on\u00a0Elastic Load Balancing\u00a0to improve workload performance by\n            allowing the load balancer to handle SSL/TLS encryption and\n            decryption process instead of having backend instances do\n            it. This can help reduce the CPU utilization on the backend\n            instances, which can improve performance and increase\n            capacity.\n          \n\n\n            Use\n            the\u00a0Network Load Balancer (NLB)\u00a0to deploy services that rely on\n            the UDP protocol, such as authentication and authorization,\n            logging, DNS, IoT, and streaming media, to improve the\n            performance and reliability of your workload. The NLB\n            distributes incoming UDP traffic across multiple targets,\n            allowing you to scale your workload horizontally, increase\n            capacity, and reduce the overhead of a single target.\n          \n\n\n            For your High Performance Computing (HPC) workloads,\n            consider using\n            the\u00a0Elastic\n            Network Adapter (ENA) Express\u00a0functionality that uses\n            the SRD protocol to improve network performance by providing\n            a higher single flow bandwidth (25 Gbps) and lower tail\n            latency (99.9 percentile) for network traffic between EC2\n            instances.\n          \n\n\n            Use\n            the\u00a0Application Load Balancer (ALB)\u00a0to route and load balance your\n            gRPC (Remote Procedure Calls) traffic between workload\n            components or between gRPC clients and services. gRPC uses\n            the TCP-based HTTP/2 protocol for transport and it provides\n            performance benefits such as lighter network footprint,\n            compression, efficient binary serialization, support for\n            numerous languages, and bi-directional streaming.\n          \n\nResources\n\nRelated documents:\n\n\n\n\nAmazon EBS - Optimized Instances\n\n\n\nApplication Load Balancer\n\n\n\nEC2\n          Enhanced Networking on Linux\n\n\n\nEC2\n          Enhanced Networking on Windows\n\n\n\nEC2\n          Placement Groups\n\n\n\nEnabling\n          Enhanced Networking with the Elastic Network Adapter (ENA) on\n          Linux Instances\n\n\n\nNetwork Load Balancer\n\n\n\nNetworking\n          Products with AWS\n\n\n\nAWS Transit Gateway\n\n\n\nTransitioning\n          to Latency-Based Routing in Amazon Route\u00a053\n\n\n\nVPC\n          Endpoints\n\n\n\nVPC\n          Flow Logs\n\n\n\nRelated videos:\n\n\n\n\nConnectivity\n          to AWS and hybrid AWS network architectures\n\n\n\nOptimizing\n          Network Performance for Amazon EC2 Instances\n\n\n\nRelated examples:\n\n\n\n\nAWS Transit Gateway and Scalable Security Solutions\n\n\n\nAWS           Networking Workshops\n\n\n Javascript is disabled or is unavailable in your browser.To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.Document ConventionsPERF04-BP04 Use load balancing to distribute traffic across\n  multiple resourcesPERF04-BP06 Choose your workload's location based on network requirementsDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.", "metadata": {"source": "https://docs.aws.amazon.com/wellarchitected/latest/framework/perf_networking_choose_network_protocols_improve_performance.html", "title": "PERF04-BP05 Choose network protocols to improve performance - AWS Well-Architected Framework", "description": "Make decisions about protocols for communication between systems and networks based on the impact to the workload\u2019s performance.", "language": "en-US"}}