{"page_content": "REL07-BP01 Use automation when obtaining or scaling resources - Reliability PillarREL07-BP01 Use automation when obtaining or scaling resources - Reliability PillarAWSDocumentationAWS Well-ArchitectedAWS Well-Architected FrameworkImplementation guidanceResourcesREL07-BP01 Use automation when obtaining or scaling\n  resources\n    When replacing impaired resources or scaling your workload, automate\n    the process by using managed AWS services, such as Amazon S3 and AWS Auto Scaling. You can also use third-party tools and AWS SDKs to\n    automate scaling.\n  \n    Managed AWS services include Amazon S3, Amazon CloudFront, AWS Auto Scaling, AWS Lambda, Amazon DynamoDB, AWS Fargate, and Amazon\n    Route\u00a053.\n  \n    AWS Auto Scaling lets you detect and replace impaired instances. It\n    also lets you build scaling plans for resources\n    including\u00a0Amazon EC2\u00a0instances and Spot\n    Fleets,\u00a0Amazon ECS\u00a0tasks,\u00a0Amazon DynamoDB\u00a0tables and indexes,\n    and\u00a0Amazon Aurora\u00a0Replicas.\n  \n    When scaling EC2 instances, ensure that you use multiple\n    Availability Zones (preferably at least three) and add or remove\n    capacity to maintain balance across these Availability Zones. ECS\n    tasks or Kubernetes pods (when using Amazon Elastic Kubernetes Service) should also be distributed across multiple Availability\n    Zones.\n  \n    When using AWS Lambda, instances scale automatically. Every time an\n    event notification is received for your function, AWS Lambda quickly\n    locates free capacity within its compute fleet and runs your code up\n    to the allocated concurrency. You need to ensure that the necessary\n    concurrency is configured on the specific Lambda, and in your\n    Service Quotas.\n  \n    Amazon S3 automatically scales to handle high request rates. For\n    example, your application can achieve at least 3,500\n    PUT/COPY/POST/DELETE or 5,500 GET/HEAD requests per second per\n    prefix in a bucket. There are no limits to the number of prefixes in\n    a bucket. You can increase your read or write performance by\n    parallelizing reads. For example, if you create 10 prefixes in an\n    Amazon S3 bucket to parallelize reads, you could scale your read\n    performance to 55,000 read requests per second.\n  \n    Configure and use Amazon CloudFront or a trusted content delivery\n    network (CDN). A CDN can provide faster end-user response times and\n    can serve requests for content from cache, therefore reducing the\n    need to scale your\u00a0workload.\n  \nCommon anti-patterns:\n\n\n\n        Implementing Auto Scaling groups for automated healing, but not\n        implementing elasticity.\n      \n\n\n        Using automatic scaling to respond to large increases in\n        traffic.\n      \n\n\n        Deploying highly stateful applications, eliminating the option\n        of elasticity.\n      \n\nBenefits of establishing this best\n    practice: Automation removes the potential for manual\n    error in deploying and decommissioning resources. Automation removes\n    the risk of cost overruns and denial of service due to slow response\n    on needs for deployment or decommissioning.\n  \nLevel of risk exposed if this best practice\n    is not established: High\n  \nImplementation guidance\n\n\n    Configure and use AWS Auto Scaling. This monitors your\n    applications and automatically adjusts capacity to maintain\n    steady, predictable performance at the lowest possible cost. Using\n    AWS Auto Scaling, you can setup application scaling for multiple\n    resources across multiple services.\n  \n\n\n\nWhat is\n                AWS Auto Scaling?\n\n\n\n Configure Auto Scaling on your Amazon EC2 instances and Spot Fleets, Amazon ECS tasks,\n                  Amazon DynamoDB tables and indexes, Amazon Aurora Replicas, and AWS Marketplace appliances as\n                  applicable. \n\n\n\nManaging\n                        throughput capacity automatically with DynamoDB Auto Scaling\n\n\n\n Use service API operations to specify the alarms, scaling policies,\n                          warm up times, and cool down times. \n\n\n\n\n    Use Elastic Load Balancing. Load balancers can distribute load by\n    path or by network connectivity.\n  \n\n\n\nWhat is\n                Elastic Load Balancing?\n\n\n\n Application Load Balancers can distribute load by path. \n\n\n\nWhat is an\n                        Application Load Balancer?\n\n\n\n Configure an Application Load Balancer to distribute traffic to different workloads based\n                          on the path under the domain name. \n\n Application Load Balancers can be used to distribute loads in a manner that integrates\n                          with AWS Auto Scaling to manage demand. \n\n\n\nUsing\n                                a load balancer with an Auto Scaling group\n\n\n\n\n\n Network Load Balancers can distribute load by connection. \n\n\n\nWhat is a\n                        Network Load Balancer?\n\n\n\n Configure a Network Load Balancer to distribute traffic to different\n                          workloads using TCP, or to have a constant set of IP addresses for your\n                          workload. \n\n Network Load Balancers can be used to distribute loads in a manner\n                          that integrates with AWS Auto Scaling to manage demand. \n\n\n\n\n    Use a highly available DNS provider. DNS names allow your users to\n    enter names instead of IP addresses to access your workloads and\n    distributes this information to a defined scope, usually globally\n    for users of the workload.\n  \n\n\n Use Amazon Route\u00a053 or a trusted DNS provider. \n\n\n\nWhat\n                    is Amazon Route\u00a053?\n\n\n\n Use Route\u00a053 to manage your CloudFront distributions and load balancers. \n\n\n Determine the domains and subdomains you are going to manage. \n\n Create appropriate record sets using ALIAS or CNAME records. \n\n\n\nWorking with\n                        records\n\n\n\n\n    Use the AWS global network to optimize the path from your users to\n    your applications. AWS Global Accelerator continually monitors the\n    health of your application endpoints and redirects traffic to\n    healthy endpoints in less than 30 seconds.\n  \n\n\n AWS Global Accelerator is a service that improves the availability and performance of your\n              applications with local or global users. It provides static IP addresses that act as a\n              fixed entry point to your application endpoints in a single or multiple AWS Regions,\n              such as your Application Load Balancers, Network Load Balancers or Amazon EC2 instances. \n\n\n\nWhat Is AWS\n                    Global Accelerator?\n\n\n\n \n    Configure and use Amazon CloudFront or a trusted content delivery\n    network (CDN). A content delivery network can provide faster\n    end-user response times and can serve requests for content that\n    may cause unnecessary scaling of your workloads.\n  \n\n\n\nWhat is Amazon CloudFront?\n\n\n\n Configure Amazon CloudFront distributions for your workloads, or use a third-party\n                  CDN. \n\n\n You can limit access to your workloads so that they are only accessible\n                      from CloudFront by using the IP ranges for CloudFront in your endpoint security groups or\n                      access policies. \n\n\n\nResources\n\nRelated documents:\n\n\n\n\nAPN\n          Partner: partners that can help you create automated compute\n          solutions\n\n\n\nAWS Auto Scaling: How Scaling Plans Work\n\n\n\nAWS Marketplace: products that can be used with auto\n          scaling\n\n\n\nManaging\n          Throughput Capacity Automatically with DynamoDB Auto\n          Scaling\n\n\n\nUsing\n          a load balancer with an Auto Scaling group\n\n\n\nWhat\n          Is AWS Global Accelerator?\n\n\n\nWhat\n          Is Amazon EC2 Auto Scaling?\n\n\n\nWhat\n          is AWS Auto Scaling?\n\n\n\nWhat\n          is Amazon CloudFront?\n\n\n\nWhat\n          is Amazon Route\u00a053?\n\n\n\nWhat\n          is Elastic Load Balancing?\n\n\n\nWhat\n          is a Network Load Balancer?\n\n\n\nWhat\n          is an Application Load Balancer?\n\n\n\nWorking\n          with records\n\n\n Javascript is disabled or is unavailable in your browser.To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.Document ConventionsDesign your workload to adapt to changes in demandREL07-BP02 Obtain resources upon detection of impairment to a\n  workloadDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.", "metadata": {"source": "https://docs.aws.amazon.com/wellarchitected/latest/reliability-pillar/rel_adapt_to_changes_autoscale_adapt.html", "title": "REL07-BP01 Use automation when obtaining or scaling resources - Reliability Pillar", "description": "When replacing impaired resources or scaling your workload, automate the process by using managed AWS services, such as Amazon S3 and AWS Auto Scaling. You can also use third-party tools and AWS SDKs to automate scaling.", "language": "en-US"}}