{"page_content": "PERF03-BP05 Implement data access patterns that utilize caching - Performance Efficiency PillarPERF03-BP05 Implement data access patterns that utilize caching - Performance Efficiency PillarAWSDocumentationAWS Well-ArchitectedAWS Well-Architected FrameworkImplementation guidanceResourcesPERF03-BP05 Implement data access patterns that utilize\n  caching\n    Implement access patterns that can benefit from caching data for\n    fast retrieval of frequently accessed data.\n  \nCommon anti-patterns:\n\n\n\n        You cache data that changes frequently.\n      \n\n\n        You rely on cached data as if it is durably stored and always\n        available.\n      \n\n\n        You don't consider the consistency of your cached data.\n      \n\n\n        You don't monitor the efficiency of your caching implementation.\n      \n\nBenefits of establishing this best\n    practice: Storing data in a cache can improve read\n    latency, read throughput, user experience, and overall efficiency,\n    as well as reduce costs.\n  \nLevel of risk exposed if this best practice\n    is not established: Medium\n  \nImplementation guidance\n\n      A cache is a software or hardware component aimed at storing data\n      so that future requests for the same data can be served faster or\n      more efficiently. The data stored in a cache can be reconstructed\n      if lost by repeating an earlier calculation or fetching it from\n      another data store.\n    \n\n      Data caching can be one of the most effective strategies to\n      improve your overall application performance and reduce burden on\n      your underlying primary data sources. Data can be cached at\n      multiple levels in the application, such as within the application\n      making remote calls, known as client-side\n      caching, or by using a fast secondary service for\n      storing the data, known as remote caching.\n    \n\nClient-side caching\n\n\n      With client-side caching, each client (an application or service\n      that queries the backend datastore) can store the results of their\n      unique queries locally for a specified amount of time. This can\n      reduce the number of requests across the network to a datastore by\n      checking the local client cache first. If the results are not\n      present, the application can then query the datastore and store\n      those results locally. This pattern allows each client to store\n      data in the closest location possible (the client itself),\n      resulting in the lowest possible latency. Clients can also\n      continue to serve some queries when the backend datastore is\n      unavailable, increasing the availability of the overall system.\n    \n\n      One disadvantage of this approach is that when multiple clients are involved, they may store the same cached data locally. This results in both duplicate storage usage and data inconsistency between those clients. One client might cache the results of a query, and one minute later another client can run the same query and get a different result.\n    \n\nRemote caching\n\n\n      To solve the issue of duplicate data between clients, a fast\n      external service, or remote cache, can be\n      used to store the queried data. Instead of checking a local data\n      store, each client will check the remote cache before querying the\n      backend datastore. This strategy allows for more consistent\n      responses between clients, better efficiency in stored data, and a\n      higher volume of cached data because the storage space scales\n      independently of clients.\n    \n\n      The disadvantage of a remote cache is that the overall system may\n      see a higher latency, as an additional network hop is required to\n      check the remote cache. Client-side caching can be used alongside\n      remote caching for multi-level caching to improve the latency.\n    \nImplementation steps\n\n\n\n            Identify databases, APIs and network services that could\n            benefit from caching. Services that have heavy read\n            workloads, have a high read-to-write ratio, or are expensive\n            to scale are candidates for caching.\n          \n\n\n\nDatabase\n                  Caching\n\n\n\nEnabling\n                  API caching to enhance responsiveness\n\n\n\n\n            Identify the appropriate type of caching strategy that best\n            fits your access pattern.\n          \n\n\n\nCaching\n                  strategies\n\n\n\nAWS             Caching Solutions\n\n\n\n\n            Follow\n            Caching\n            Best Practices for your data store.\n          \n\n\n            Configure a cache invalidation strategy, such as a\n            time-to-live (TTL), for all data that balances freshness of\n            data and reducing pressure on backend datastore.\n          \n\n\n            Enable features such as automatic connection retries,\n            exponential backoff, client-side timeouts, and connection\n            pooling in the client, if available, as they can improve\n            performance and reliability.\n          \n\n\n\nBest\n                  practices: Redis clients and Amazon ElastiCache for Redis\n\n\n\n\n            Monitor cache hit rate with a goal of 80% or higher. Lower\n            values may indicate insufficient cache size or an access\n            pattern that does not benefit from caching.\n          \n\n\n\nWhich\n                  metrics should I monitor?\n\n\n\nBest\n                  practices for monitoring Redis workloads on Amazon ElastiCache\n\n\n\nMonitoring\n                  best practices with Amazon ElastiCache for Redis using\n                  Amazon CloudWatch\n\n\n\n\n            Implement\n            data\n            replication to offload reads to multiple instances\n            and improve data read performance and availability.\n          \n\nResources\n\nRelated documents:\n\n\n\n\nUsing\n          the Amazon ElastiCache Well-Architected Lens\n\n\n\nMonitoring\n          best practices with Amazon ElastiCache for Redis using Amazon CloudWatch\n\n\n\nWhich\n          Metrics Should I Monitor?\n\n\n\nPerformance\n          at Scale with Amazon ElastiCache whitepaper\n\n\n\nCaching\n          challenges and strategies\n\n\n\nRelated videos:\n\n\n\n\nAmazon ElastiCache Learning Path\n\n\n\nDesign for\n          success with Amazon ElastiCache best practices\n\n\n\nRelated examples:\n\n\n\n\nBoosting\n          MySQL database performance with Amazon ElastiCache for Redis\n\n\n Javascript is disabled or is unavailable in your browser.To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.Document ConventionsPERF03-BP04 Implement strategies to improve query performance\n  in data storeNetworking and content deliveryDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.", "metadata": {"source": "https://docs.aws.amazon.com/wellarchitected/latest/performance-efficiency-pillar/perf_data_access_patterns_caching.html", "title": "PERF03-BP05 Implement data access patterns that utilize caching - Performance Efficiency Pillar", "description": "Implement access patterns that can benefit from caching data for fast retrieval of frequently accessed data.", "language": "en-US"}}