{"page_content": "Availability - Reliability PillarAvailability - Reliability PillarAWSDocumentationAWS Well-ArchitectedAWS Well-Architected FrameworkAvailability\nAvailability (also known as service availability)\n        is both a commonly used metric to quantitatively measure resiliency, as well as a target\n        resiliency objective. \n\n\nAvailability is the\n            percentage of time that a workload is available for use.\n          \n\nAvailable for use means that it performs its agreed function\n        successfully when required.  This percentage is calculated over a period of time, such as a month, year, or trailing\n        three years. Applying the strictest possible interpretation, availability is reduced anytime\n        that the application isn\u2019t operating normally, including both scheduled and unscheduled\n        interruptions. We define availability as follows: \n\n\n\nAvailability is a percentage uptime (such as 99.9%) over a period of time (commonly\n            a month or year) \n\n Common short-hand refers only to the \u201cnumber of nines\u201d; for example, \u201cfive nines\u201d\n            translates to being 99.999% available \n\nSome customers choose to exclude scheduled service downtime (for example, planned\n            maintenance) from the Total Time in the formula.\n            However, this is not advised, as your users will likely want to use your service during\n            these times. \n\n        Here is a table of common application availability design goals\n        and the maximum length of time that interruptions can occur\n        within a year while still meeting the goal. The table contains\n        examples of the types of applications we commonly see at each\n        availability tier. Throughout this document, we refer to these\n        values.\n      \n\n\n                Availability\n              \n\n                Maximum Unavailability (per year)\n              \n\n                Application Categories\n              \n\n\n\n\n99%\n\n\n                3 days 15 hours\n              \n\n                Batch processing, data extraction, transfer, and load\n                jobs\n              \n\n\n\n99.9%\n\n\n                8 hours 45 minutes\n              \n\n                Internal tools like knowledge management, project\n                tracking\n              \n\n\n\n99.95%\n\n\n                4 hours 22 minutes\n              \n\n                Online commerce, point of sale\n              \n\n\n\n99.99%\n\n\n                52 minutes\n              \n\n                Video delivery, broadcast\n                workloads\n\n\n\n\n99.999%\n\n\n                5 minutes\n              \n\n                ATM transactions, telecommunications\n                workloads\n\n\nMeasuring availability based on requests. For your\n        service it may be easier to count successful and failed requests instead of \u201ctime\n        available for use\u201d. In this case the following calculation can be used:\n      \n\nThis is often measured for one-minute or five-minute periods. Then a monthly uptime\n        percentage (time-base availability measurement) can be calculated from the average of\n        these periods. If no requests are received in a given period it is counted at 100%\n        available for that time.\n      \n\n\nCalculating availability with hard\n        dependencies. Many systems have hard dependencies on\n        other systems, where an interruption in a dependent system\n        directly translates to an interruption of the invoking system.\n        This is opposed to a soft dependency, where a failure of the\n        dependent system is compensated for in the application. Where\n        such hard dependencies occur, the invoking system\u2019s availability\n        is the product of the dependent systems\u2019 availabilities. For\n        example, if you have a system designed for 99.99% availability\n        that has a hard dependency on two other independent systems that\n        each are designed for 99.99% availability, the workload can\n        theoretically achieve 99.97% availability:\n      \n            Availinvok\u2005\u00d7\u2005Availdep1\u2005\u00d7\u2005Availdep2 = Availworkload\n\n        99.99%\u2005\u00d7\u200599.99%\u2005\u00d7\u200599.99%\u2004=\u200499.97%\n      \n        It\u2019s therefore important to understand your dependencies and\n        their availability design goals as you calculate your own.\n      \nCalculating availability with redundant components. When a\n        system involves the use of independent, redundant components (for example, redundant\n        resources in different Availability Zones), the theoretical availability is computed as 100%\n        minus the product of the component failure rates. For example, if a system makes use of two\n        independent components, each with an availability of 99.9%, the effective availability of\n        this dependency is 99.9999%: \n\n\n          Availeffective\u2004=\u2004AvailMAX\u2005\u2212\u2005((100%\u2212Availdependency)\u00d7(100%\u2212Availdependency))  99.9999% = 100%\u2005\u2212\u2005(0.1%\u00d70.1%) \nShortcut calculation: If the availabilities of all components\n        in your calculation consist solely of the digit nine, then you can sum the count\n        of the number of nines digits to get your answer. In the above example two \n        redundant, independent components with three nines availability results in six nines.\n      \nCalculating dependency\n        availability. Some dependencies provide guidance on\n        their availability, including availability design goals for many\n        AWS services (see\n        Appendix\n        A: Designed-For Availability for Select AWS Services).\n        But in cases where this isn\u2019t available (for example, a\n        component where the manufacturer does not publish availability\n        information), one way to estimate is to determine the\n        Mean Time Between Failure\n        (MTBF) and Mean Time to\n        Recover (MTTR). An availability estimate can be\n        established by:\n      \n\n\n        For example, if the MTBF is 150 days and the MTTR is 1 hour, the\n        availability estimate is 99.97%.\n      \n        For additional details, see\n        \n        Availability and Beyond: Understanding and improving the resilience of distributed systems on AWS, which\n        can help you calculate your availability.\n      \nCosts for availability.\n        Designing applications for higher levels of availability\n        typically results in increased cost, so it\u2019s appropriate to\n        identify the true availability needs before embarking on your\n        application design. High levels of availability impose stricter\n        requirements for testing and validation under exhaustive failure\n        scenarios. They require automation for recovery from all manner\n        of failures, and require that all aspects of system operations\n        be similarly built and tested to the same standards. For\n        example, the addition or removal of capacity, the deployment or\n        rollback of updated software or configuration changes, or the\n        migration of system data must be conducted to the desired\n        availability goal. Compounding the costs for software\n        development, at very high levels of availability, innovation\n        suffers because of the need to move more slowly in deploying\n        systems. The guidance, therefore, is to be thorough in applying\n        the standards and considering the appropriate availability\n        target for the entire lifecycle of operating the system.\n      \n        Another way that costs escalate in systems that operate with\n        higher availability design goals is in the selection of\n        dependencies. At these higher goals, the set of software or\n        services that can be chosen as dependencies diminishes based on\n        which of these services have had the deep investments we\n        previously described. As the availability design goal increases,\n        it\u2019s typical to find fewer multi-purpose services (such as a\n        relational database) and more purpose-built services. This is\n        because the latter are easier to evaluate, test, and automate,\n        and have a reduced potential for surprise interactions with\n        included but unused functionality.\n       Javascript is disabled or is unavailable in your browser.To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.Document ConventionsResiliency, and the components of reliabilityDisaster Recovery (DR) objectivesDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.", "metadata": {"source": "https://docs.aws.amazon.com/wellarchitected/latest/reliability-pillar/availability.html", "title": "Availability - Reliability Pillar", "description": "Availability (also known as service availability ) is both a commonly used metric to quantitatively measure resiliency, as well as a target resiliency objective.", "language": "en-US"}}