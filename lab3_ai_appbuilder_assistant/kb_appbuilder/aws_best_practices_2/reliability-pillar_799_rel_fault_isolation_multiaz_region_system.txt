{"page_content": "REL10-BP01 Deploy the workload to multiple locations - Reliability PillarREL10-BP01 Deploy the workload to multiple locations - Reliability PillarAWSDocumentationAWS Well-ArchitectedAWS Well-Architected FrameworkImplementation guidanceResourcesREL10-BP01 Deploy the workload to multiple locations\n    Distribute workload data and resources across multiple Availability\n    Zones or, where necessary, across AWS Regions. These locations can\n    be as diverse as required.\n  \n    One of the bedrock principles for service design in AWS is the\n    avoidance of single points of failure in underlying physical\n    infrastructure. This motivates us to build software and systems that\n    use multiple Availability Zones and are resilient to failure of a\n    single zone. Similarly, systems are built to be resilient to failure\n    of a single compute node, single storage volume, or single instance\n    of a database. When building a system that relies on redundant\n    components, it\u2019s important to ensure that the components operate\n    independently, and in the case of AWS Regions, autonomously. The\n    benefits achieved from theoretical availability calculations with\n    redundant components are only valid if this holds true.\n  \nAvailability Zones (AZs)\n\n    AWS Regions are composed of multiple Availability Zones that are\n    designed to be independent of each other. Each Availability Zone is\n    separated by a meaningful physical distance from other zones to\n    avoid correlated failure scenarios due to environmental hazards like\n    fires, floods, and tornadoes. Each Availability Zone also has\n    independent physical infrastructure: dedicated connections to\n    utility power, standalone backup power sources, independent\n    mechanical services, and independent network connectivity within and\n    beyond the Availability Zone. This design limits faults in any of\n    these systems to just the one affected AZ. Despite being\n    geographically separated, Availability Zones are located in the same\n    regional area which allows high-throughput, low-latency networking.\n    The entire AWS Region (across all Availability Zones, consisting of\n    multiple physically independent data centers) can be treated as a\n    single logical deployment target for your workload, including the\n    ability to synchronously replicate data (for example, between\n    databases). This allows you to use Availability Zones in an\n    active/active or active/standby configuration.\n  \n    Availability Zones are independent, and therefore workload\n    availability is increased when the workload is architected to use\n    multiple zones. Some AWS services (including the Amazon EC2 instance\n    data plane) are deployed as strictly zonal services where they have\n    shared fate with the Availability Zone they are in. Amazon EC2\n    instances in the other AZs will however be unaffected and continue\n    to function. Similarly, if a failure in an Availability Zone causes\n    an Amazon Aurora database to fail, a read-replica Aurora instance in\n    an unaffected AZ can be automatically promoted to primary. Regional\n    AWS services, such as Amazon DynamoDB on the other hand internally\n    use multiple Availability Zones in an active/active configuration to\n    achieve the availability design goals for that service, without you\n    needing to configure AZ placement.\n  \n\nFigure 9: Multi-tier architecture deployed across three\n        Availability Zones. Note that Amazon S3 and Amazon DynamoDB are\n        always Multi-AZ automatically. The ELB also is deployed to all three\n        zones.\n\n    While AWS control planes typically provide the ability to manage\n    resources within the entire Region (multiple Availability Zones),\n    certain control planes (including Amazon EC2 and Amazon EBS) have\n    the ability to filter results to a single Availability Zone. When\n    this is done, the request is processed only in the specified\n    Availability Zone, reducing exposure to disruption in other\n    Availability Zones. This AWS CLI example illustrates getting Amazon EC2 instance information from only the\u00a0us-east-2c\u00a0Availability Zone:\n   AWS ec2 describe-instances --filters Name=availability-zone,Values=us-east-2c\n  \nAWS Local Zones\n\n    AWS Local Zones act similarly to Availability Zones within their\n    respective AWS Region in that they can be selected as a placement\n    location for zonal AWS resources such as subnets and EC2 instances.\n    What makes them special is that they are located not in the\n    associated AWS Region, but near large population, industry, and IT\n    centers where no AWS Region exists today. Yet they still retain\n    high-bandwidth, secure connection between local workloads in the\n    local zone and those running in the AWS Region. You should use AWS\n    Local Zones to deploy workloads closer to your users for low-latency\n    requirements.\n  \nAmazon Global Edge Network\n\n    Amazon Global Edge Network consists of edge locations in cities\n    around the world. Amazon CloudFront uses this network to deliver\n    content to end users with lower latency. AWS Global Accelerator\n    allows you to create your workload endpoints in these edge\n    locations to provide onboarding to the AWS global network close to\n    your users. Amazon API Gateway allows edge-optimized API endpoints\n    using a CloudFront distribution to facilitate client access through\n    the closest edge location.\n  \nAWS Regions\n\n    AWS Regions are designed to be autonomous, therefore, to use a\n    multi-Region approach you would deploy dedicated copies of services\n    to each Region.\n  \n    A multi-Region approach is common for\u00a0disaster\n    recovery\u00a0strategies to meet recovery objectives when\n    one-off large-scale events occur.\n    See\u00a0Plan\n    for Disaster Recovery (DR)\u00a0for more information on\n    these strategies. Here however, we focus instead\n    on\u00a0availability, which seeks to deliver a mean\n    uptime objective over time. For high-availability objectives, a\n    multi-region architecture will generally be designed to be\n    active/active, where each service copy (in their respective regions)\n    is active (serving requests).\n  Recommendation\n    Availability goals for most workloads can be satisfied using\n    a Multi-AZ strategy within a single AWS Region. Consider\n    multi-Region architectures only when workloads have extreme\n    availability requirements, or other business goals, that\n    require a multi-Region architecture.\n  \n    AWS provides you with the capabilities to operate services\n    cross-region. For example, AWS provides continuous, asynchronous\n    data replication of data using Amazon Simple Storage Service (Amazon S3) Replication, Amazon RDS Read Replicas (including Aurora Read\n    Replicas), and Amazon DynamoDB Global Tables. With continuous\n    replication, versions of your data are available for near immediate\n    use in each of your active Regions.\n  \n    Using AWS CloudFormation, you can define your infrastructure and\n    deploy it consistently across AWS accounts and across AWS Regions.\n    And AWS CloudFormation StackSets extends this functionality by\n    allowing you to create, update, or delete AWS CloudFormation stacks\n    across multiple accounts and regions with a single operation. For\n    Amazon EC2 instance deployments, an AMI (Amazon Machine Image) is\n    used to supply information such as hardware configuration and\n    installed software. You can implement an Amazon EC2 Image Builder\n    pipeline that creates the AMIs you need and copy these to your\n    active regions. This ensures that these Golden\n    AMIs have everything you need to deploy and scale-out\n    your workload in each new region.\n  \n    To route traffic, both Amazon Route\u00a053 and AWS Global Accelerator\n    permit the definition of policies that determine which users go to\n    which active regional endpoint. With Global Accelerator you set a\n    traffic dial to control the percentage of traffic that is directed\n    to each application endpoint. Route\u00a053 supports this percentage\n    approach, and also multiple other available policies including\n    geoproximity and latency based ones. Global Accelerator\n    automatically leverages the extensive network of AWS edge servers,\n    to onboard traffic to the AWS network backbone as soon as possible,\n    resulting in lower request latencies.\n  \n    All of these capabilities operate so as to preserve each Region\u2019s\n    autonomy. There are very few exceptions to this approach, including\n    our services that provide global edge delivery (such as Amazon CloudFront and Amazon Route\u00a053), along with the control plane for\n    the AWS Identity and Access Management (IAM) service. Most services\n    operate entirely within a single Region.\n  \nOn-premises data center\n\n    For workloads that run in an on-premises data center, architect a\n    hybrid experience when possible. AWS Direct Connect provides a\n    dedicated network connection from your premises to AWS allowing you\n    to run in both.\n  \n    Another option is to run AWS infrastructure and services on premises\n    using AWS Outposts. AWS Outposts is a fully managed service that\n    extends AWS infrastructure, AWS services, APIs, and tools to your\n    data center. The same hardware infrastructure used in the AWS Cloud\n    is installed in your data center. AWS Outposts are then connected to\n    the nearest AWS Region. You can then use AWS Outposts to support\n    your workloads that have low latency or local data processing\n    requirements.\n  \nLevel of risk exposed if this best practice\n    is not established: High\n  \nImplementation guidance\n\n \n       Use multiple Availability Zones and AWS Regions. Distribute\n       workload data and resources across multiple Availability Zones or,\n       where necessary, across AWS Regions. These locations can be as\n       diverse as required.\n     \n\n\n Regional services are inherently deployed across Availability Zones.", "metadata": {"source": "https://docs.aws.amazon.com/wellarchitected/latest/reliability-pillar/rel_fault_isolation_multiaz_region_system.html", "title": "REL10-BP01 Deploy the workload to multiple locations - Reliability Pillar", "description": "Distribute workload data and resources across multiple Availability Zones or, where necessary, across AWS Regions. These locations can be as diverse as required.", "language": "en-US"}}