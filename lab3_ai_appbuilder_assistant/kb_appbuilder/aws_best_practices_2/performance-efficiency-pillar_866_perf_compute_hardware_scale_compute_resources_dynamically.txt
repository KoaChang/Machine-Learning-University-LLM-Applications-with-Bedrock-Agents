{"page_content": "PERF02-BP05 Scale your compute resources dynamically - Performance Efficiency PillarPERF02-BP05 Scale your compute resources dynamically - Performance Efficiency PillarAWSDocumentationAWS Well-ArchitectedAWS Well-Architected FrameworkImplementation guidanceResourcesPERF02-BP05 Scale your compute resources dynamically\n    Use the elasticity of the cloud to scale your compute resources up\n    or down dynamically to match your needs and avoid over- or\n    under-provisioning capacity for your workload.\n  \nCommon anti-patterns:\n\n\n\n        You react to alarms by manually increasing capacity.\n      \n\n\n        You use the same sizing guidelines (generally static\n        infrastructure) as in on-premises.\n      \n\n\n        You leave increased capacity after a scaling event instead of\n        scaling back down.\n      \n\nBenefits of establishing this best\n    practice: Configuring and testing the elasticity of\n    compute resources can help you save money, maintain performance\n    benchmarks, and improve reliability as traffic changes.\n  \nLevel of risk exposed if this best practice\n    is not established: High\n  \nImplementation guidance\n\n      AWS provides the flexibility to scale your resources up or down\n      dynamically through a variety of scaling mechanisms in order to\n      meet changes in demand. Combined with compute-related metrics, a\n      dynamic scaling allows workloads to automatically respond to\n      changes and use the optimal set of compute resources to achieve\n      its goal.\n    \n\n      You can use a number of different approaches to match supply of\n      resources with demand.\n    \n\n\n\nTarget-tracking approach:\u00a0Monitor your scaling metric and\n          automatically increase or decrease capacity as you need it. \n\n\nPredictive scaling:\u00a0Scale in anticipation of daily and\n          weekly trends. \n\n\nSchedule-based approach:\u00a0Set your own scaling schedule\n          according to predictable load changes. \n\n\nService scaling:\u00a0Choose services (like serverless) that\n          that automatically scale by design. \n\n\n      You must ensure that workload deployments can handle both scale-up\n      and scale-down events.\n    \nImplementation steps\n\n\n\n            Compute instances, containers, and functions provide\n            mechanisms for elasticity, either in combination with\n            autoscaling or as a feature of the service. Here are some\n            examples of automatic scaling mechanisms:\n          \n\n\n\n                    Autoscaling Mechanism\n                  \n\n                    Where to use\n                  \n\n\n\n\nAmazon EC2 Auto Scaling\n\n\n                    To ensure you have the correct number of\n                    Amazon EC2 instances available to handle the user load\n                    for your application.\n                  \n\n\n\nApplication Auto Scaling\n\n\n                    To automatically scale the resources for individual AWS\n                    services beyond Amazon EC2 such as\n                    AWS Lambda functions or\n                    Amazon Elastic Container Service (Amazon ECS) services.\n                  \n\n\n\nKubernetes\n                      Cluster Autoscaler/Karpenter\n\n\n                    To automatically scale Kubernetes clusters.\n                  \n\n\n\n\n            Scaling is often discussed related to compute services like\n            Amazon EC2 Instances or AWS Lambda functions. Be sure to\n            also consider the configuration of non-compute services like\n            AWS Glue to match the demand.\n          \n\n\n            Verify that the metrics for scaling match the\n            characteristics of the workload being deployed. If you are\n            deploying a video transcoding application, 100% CPU\n            utilization is expected and should not be your primary\n            metric. Use the depth of the transcoding job queue instead.\n            You can use a\n            customized\n            metric for your scaling policy if required. To choose\n            the right metrics, consider the following guidance for Amazon EC2:\n          \n\n\n\n                The metric should be a valid utilization metric and\n                describe how busy an instance is.\n              \n\n\n                The metric value must increase or decrease\n                proportionally to the number of instances in the Auto Scaling group.\n              \n\n\n\n            Make sure that you use\n            dynamic\n            scaling instead of\n            manual\n            scaling for your Auto Scaling group. We also\n            recommend that you use\n            target\n            tracking scaling policies in your dynamic scaling.\n          \n\n\n            Verify that workload deployments can handle both scaling\n            events (up and down). As an example, you can use\n            Activity\n            history to verify a scaling activity for an Auto Scaling group.\n          \n\n\n            Evaluate your workload for predictable patterns and\n            proactively scale as you anticipate predicted and planned\n            changes in demand. With predictive scaling, you can\n            eliminate the need to overprovision capacity. For more detail, \n            see Predictive\n              Scaling with Amazon EC2 Auto Scaling.\n          \n\nResources\n\nRelated documents:\n\n\n\n\nCloud\n          Compute with AWS\n\n\n\nAmazon EC2\n          Instance Types\n\n\n\nAmazon ECS\n          Containers: Amazon ECS Container Instances\n\n\n\nAmazon EKS\n          Containers: Amazon EKS Worker Nodes\n\n\n\nFunctions:\n          Lambda Function Configuration\n\n\n\nProcessor\n          State Control for Your Amazon EC2 Instance\n\n\n\nDeep\n          Dive on Amazon ECS Cluster Auto Scaling\n\n\n\nIntroducing\n          Karpenter \u2013 An Open-Source High-Performance Kubernetes Cluster\n          Autoscaler\n\n\n\nRelated videos:\n\n\n\n\nAmazon EC2 foundations\n\n\n\nBetter,\n          faster, cheaper compute: Cost-optimizing Amazon EC2\n\n\n\nOptimize\n          performance and cost for your AWS compute\n\n\n\nPowering\n          next-gen Amazon EC2: Deep dive into the Nitro system\n\n\n\nBuild\n          a cost-, energy-, and resource-efficient compute\n          environment\n\n\n\nRelated examples:\n\n\n\n\nAmazon EC2 Auto Scaling Group Examples\n\n\n\nImplement Autoscaling with Karpenter\n\n\n Javascript is disabled or is unavailable in your browser.To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.Document ConventionsPERF02-BP04 Configure and right-size compute resourcesPERF02-BP06 Use optimized hardware-based compute\n  acceleratorsDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.", "metadata": {"source": "https://docs.aws.amazon.com/wellarchitected/latest/performance-efficiency-pillar/perf_compute_hardware_scale_compute_resources_dynamically.html", "title": "PERF02-BP05 Scale your compute resources dynamically - Performance Efficiency Pillar", "description": "Use the elasticity of the cloud to scale your compute resources up or down dynamically to match your needs and avoid over- or under-provisioning capacity for your workload.", "language": "en-US"}}