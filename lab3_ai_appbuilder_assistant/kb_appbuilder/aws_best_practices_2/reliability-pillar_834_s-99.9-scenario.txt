{"page_content": "3 9s (99.9%) scenario - Reliability Pillar3 9s (99.9%) scenario - Reliability PillarAWSDocumentationAWS Well-ArchitectedAWS Well-Architected FrameworkMonitor resourcesAdapt to changes in demandImplement changeBack up dataArchitect for resiliencyTest resiliencyPlan for disaster recovery (DR)Availability design goalSummary3 9s (99.9%) scenario\n        The next availability goal is for applications for which it\u2019s\n        important to be highly available, but they can tolerate short\n        periods of unavailability. This type of workload is typically\n        used for internal operations that have an effect on employees\n        when they are down. This type of workload can also be\n        customer-facing, but are not high revenue for the business and\n        can tolerate a longer recovery time or recovery point. Such\n        workloads include administrative applications for account or\n        information management.\n      \n        We can improve availability for workloads by using two\n        Availability Zones for our deployment and by separating the\n        applications to separate tiers.\n      \nMonitor resources\n\n          Monitoring will be expanded to alert on the availability of\n          the website over all by checking for an HTTP 200 OK status on\n          the home page. In addition, there will be alerting on every\n          replacement of a web server and when the database fails over.\n          We will also monitor the static content on Amazon S3 for\n          availability and alert if it becomes unavailable. Logging will\n          be aggregated for ease of management and to help in root cause\n          analysis.\n        \nAdapt to changes in demand\n\n          Automatic scaling is configured to monitor CPU utilization on\n          EC2 instances, and add or remove instances to maintain the CPU\n          target at 70%, but with no fewer than one EC2 instance per\n          Availability Zone. If load patterns on our RDS instance\n          indicate that scale up is needed, we will change the instance\n          type during a maintenance window.\n        \nImplement change\n\n          The infrastructure deployment technologies remain the same as\n          the previous scenario.\n        \n\n          Delivery of new software is on a fixed schedule of every two\n          to four weeks. Software updates will be automated, not using\n          canary or blue/green deployment patterns, but rather, using\n          replace in place. The decision to roll back will be made using\n          the runbook.\n        \n\n          We will have playbooks for establishing root cause of\n          problems. After the root cause has been identified, the\n          correction for the error will be identified by a combination\n          of the operations and development teams. The correction will\n          be deployed after the fix is developed.\n        \nBack up data\n\n          Backup and restore can be done using Amazon RDS. It will be\n          run regularly using a runbook to ensure that we can meet\n          recovery requirements.\n        \nArchitect for resiliency\n We can improve availability for applications by using two Availability Zones for our\n          deployment and by separating the applications to separate tiers. We will use services that\n          work across multiple Availability Zones, such as Elastic Load Balancing, Auto Scaling and Amazon RDS Multi-AZ with\n          encrypted storage via AWS Key Management Service. This will ensure tolerance to failures on the resource\n          level and on the Availability Zone level. \n The load balancer will only route traffic to healthy application instances. The\n          health check needs to be at the data plane/application layer indicating the capability of\n          the application on the instance. This check should not be against the control plane. A\n          health check URL for the web application will be present and configured for use by the\n          load balancer and Auto Scaling, so that instances that fail are removed and replaced. Amazon RDS will\n          manage the active database engine to be available in the second Availability Zone if the\n          instance fails in the primary Availability Zone, then repair to restore to the same\n          resiliency. \n\n          After we have separated the tiers, we can use distributed\n          system resiliency patterns to increase the reliability of the\n          application so that it can still be available even when the\n          database is temporarily unavailable during an Availability\n          Zone failover.\n        \nTest resiliency\n\n          We do functional testing, same as in the previous scenario. We\n          do not test the self-healing capabilities of ELB, automatic\n          scaling, or RDS failover.\n        \n\n          We will have playbooks for common database problems,\n          security-related incidents, and failed deployments.\n        \nPlan for disaster recovery (DR)\n\n          Runbooks exist for total workload recovery and common\n          reporting. Recovery uses backups stored in the same region as\n          the workload.\n        \nAvailability design goal\n\n          We assume that at least some failures will require a manual\n          decision to run recovery. However with the greater\n          automation in this scenario, we assume that only two events\n          per year will require this decision. We take 30 minutes to\n          decide to run recovery, and assume that recovery is\n          completed within 30 minutes. This implies 60 minutes to\n          recover from failure. Assuming two incidents per year, our\n          estimated impact time for the year is 120 minutes.\n        \n\n          This means that the upper limit on availability is 99.95%. The\n          actual availability also depends on the real rate of failure,\n          the duration of the failure, and how quickly each failure\n          actually recovers. For this architecture, we require the\n          application to be briefly offline for updates, but these\n          updates are automated. We estimate 150 minutes per year for\n          this: 15 minutes per change, 10 times per year. This adds up\n          to 270 minutes per year when the service is not available, so\n          our availability design\n          goal is 99.9%.\n        \nSummary\n\n\n\nTopic\n\n\nImplementation\n\n\n\n\n\n                  Monitor resources\n                \n\n                  Site health check only; alerts sent when down.\n                \n\n\n\n                  Adapt to changes in demand\n                \n\n                  ELB for web and automatic scaling application tier;\n                  resizing Multi-AZ RDS.\n                \n\n\n\n                  Implement change\n                \n\n                  Automated deploy in place and runbook for rollback.\n                \n\n\n\n                  Back up data\n                \n\n                  Automated backups via RDS to meet RPO and runbook for\n                  restoring.\n                \n\n\n\n                  Architect for resiliency\n                \n\n                  Automatic scaling to provide self-healing web and\n                  application tier; RDS is Multi-AZ.\n                \n\n\n\n                  Test resiliency\n                \n\n                  ELB and application are self-healing; RDS is Multi-AZ;\n                  no explicit testing.\n                \n\n\n\n                  Plan for disaster recovery (DR)\n                \n\n                  Encrypted backups via RDS to same AWS Region.\n                \n\n\n\n\n Javascript is disabled or is unavailable in your browser.To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.Document Conventions2 9s (99%) scenario 4 9s (99.99%) scenarioDid this page help you? - YesThanks for letting us know we're doing a good job!If you've got a moment, please tell us what we did right so we can do more of it.Did this page help you? - NoThanks for letting us know this page needs work. We're sorry we let you down.If you've got a moment, please tell us how we can make the documentation better.", "metadata": {"source": "https://docs.aws.amazon.com/wellarchitected/latest/reliability-pillar/s-99.9-scenario.html", "title": "3 9s (99.9%) scenario - Reliability Pillar", "description": "The next availability goal is for applications for which it\u2019s important to be highly available, but they can tolerate short periods of unavailability. This type of workload is typically used for internal operations that have an effect on employees when they are down. This type of workload can also be customer-facing, but are not high revenue for the business and can tolerate a longer recovery time or recovery point. Such workloads include administrative applications for account or information management.", "language": "en-US"}}