{"page_content": "5 9s (99.999%) or higher scenario with a recovery time under one minute - Reliability Pillar5 9s (99.999%) or higher scenario with a recovery time under one minute - Reliability PillarAWSDocumentationAWS Well-ArchitectedAWS Well-Architected FrameworkMonitor resourcesAdapt to changes in demandImplement changeBack up dataArchitect for resiliencyTest resiliencyPlan for disaster recovery (DR)Availability design goal5 9s (99.999%) or higher scenario with a recovery time under one minute\n        This availability goal for applications requires almost no\n        downtime or data loss for specific times. Applications that\n        could have this availability goal include, for example certain\n        banking, investing, finance, government, and critical business\n        applications that are the core business of an extremely\n        large-revenue generating business. The desire is to have\n        strongly consistent data stores and complete redundancy at all\n        layers. We have selected a SQL-based data store. However, in\n        some scenarios, we will find it difficult to achieve a very\n        small RPO. If you can partition your data, it\u2019s possible to have\n        no data loss. This might require you to add application logic\n        and latency to ensure that you have consistent data between\n        geographic locations, as well as the capability to move or copy\n        data between partitions. Performing this partitioning might be\n        easier if you use a NoSQL database.\n       We can improve availability further by using an Active-Active\n        approach across multiple AWS Regions. The workload will be deployed in all desired Regions\n        that are statically stable across regions (so the remaining regions can\n        handle load with the loss of one region). A routing layer directs\n        traffic to geographic locations that are healthy and automatically changes the destination\n        when a location is unhealthy, as well as temporarily stopping the data replication layers.\n        Amazon Route 53 offers 10-second interval health checks and also offers TTL on your record\n        sets as low as one second. \nMonitor resources\n\n          Same as the 3\u00bd 9s scenario, plus alerting when a Region is\n          detected as unhealthy, and traffic is routed away from it.\n        \nAdapt to changes in demand\n\n          Same as the 3\u00bd 9s scenario.\n        \nImplement change\n\n          The deployment pipeline will have a full test suite, including\n          performance, load, and failure injection testing. We will\n          deploy updates using canary or blue/green deployments to one\n          isolation zone at a time, in one Region before starting at the\n          other. During the deployment, the old versions will still be\n          kept running on instances to facilitate a faster rollback.\n          These are fully automated, including a rollback if KPIs\n          indicate a problem. Monitoring will include success metrics as\n          well as alerting when problems occur.\n        \n\n          Runbooks will exist for rigorous reporting requirements and\n          performance tracking. If successful operations are trending\n          towards failure to meet performance or availability goals, a\n          playbook will be used to establish what is causing the trend.\n          Playbooks will exist for undiscovered failure modes and\n          security incidents. Playbooks will also exist for establishing\n          root cause of failures.\n        \n\n          The team that builds the website also operates the website.\n          That team will identify the correction of error of any\n          unexpected failure and prioritize the fix to be deployed after\n          it\u2019s implemented. We will also engage with AWS Support for\n          Infrastructure Event Management.\n        \nBack up data\n\n          Same as the 3\u00bd 9s scenario.\n        \nArchitect for resiliency\n\n          The applications should be built using the\n          software/application resiliency patterns. It\u2019s possible that\n          many other routing layers may be required to implement the\n          needed availability. The complexity of this additional\n          implementation should not be underestimated. The application\n          will be implemented in deployment fault isolation zones, and\n          partitioned and deployed such that even a Region wide-event\n          will not affect all customers.\n        \nTest resiliency\n\n          We will validate the architecture through game days using\n          runbooks to ensure that we can perform the tasks and not\n          deviate from the procedures.\n        \nPlan for disaster recovery (DR)\n\nActive-Active multi-region deployment with complete workload\n          infrastructure and data in multiple regions. Using a read local, write global strategy,\n          one region is the primary database for all writes, and data is replicated for reads to\n          other regions. If the primary DB region fails, a new DB will need to be promoted. Read\n          local, write global has users assigned to a home region where DB writes are handled. This\n          lets users read or write from any region, but requires complex logic to manage potential\n          data conflicts across writes in different regions. \n\n          When a region is detected as unhealthy, the routing layer\n          automatically routes traffic to the remaining healthy regions.\n          No manual intervention is required.\n        \n\n          Data stores must be replicated between the Regions in a manner\n          that can resolve potential conflicts. Tools and automated\n          processes will need to be created to copy or move data between\n          the partitions for latency reasons and to balance requests or\n          amounts of data in each partition. Remediation of the data\n          conflict resolution will also require additional operational\n          runbooks.\n        \nAvailability design goal\n\n          We assume that heavy investments are made to automate all\n          recovery, and that recovery can be completed within one\n          minute. We assume no manually invoke recoveries, but up to\n          one automated recovery action per quarter. This implies four\n          minutes per year to recover. We assume that the application is\n          online continuously through updates. Based on this, our\n          availability design goal is\n          99.999%.\n        \n\nSummary\n\n\n\n\nTopic\n\n\nImplementation\n\n\n\n\n\n                  Monitor resources\n                \n\n                  Health checks at all layers, including DNS health at\n                  AWS Region level, and on KPIs; alerts sent when\n                  configured alarms are tripped; alerting on all\n                  failures. Operational meetings are rigorous to detect\n                  trends and manage to design goals.\n                \n\n\n\n                  Adapt to changes in demand\n                \n\n                  ELB for web and automatic scaling application tier;\n                  automatic scaling storage and read replicas in\n                  multiple zones in the active and passive regions for\n                  Aurora RDS. Data and infrastructure synchronized\n                  between AWS Regions for static stability.\n                \n\n\n\n                  Implement change\n                \n\n                  Automated deploy via canary or blue/green and\n                  automated rollback when KPIs or alerts indicate\n                  undetected problems in application, deployments are\n                  made to one isolation zone in one AWS Region at a\n                  time.\n                \n\n\n\n                  Back up data\n                \n\n                  Automated backups in each AWS Region via RDS to meet\n                  RPO and automated restoration that is practiced\n                  regularly in a game day. Aurora RDS and S3 data is\n                  automatically and asynchronously replicated from\n                  active to passive region.\n                \n\n\n\n                  Architect for resiliency\n                \n\n                  Implemented fault isolation zones for the application;\n                  auto scaling to provide self-healing web and\n                  application tier; RDS is Multi-AZ; regional failover\n                  automated.\n                \n\n\n\n                  Test resiliency\n                \n\n                  Component and isolation zone fault testing is in\n                  pipeline and practiced with operational staff\n                  regularly in a game day; playbooks exist for\n                  diagnosing unknown problems; and a Root Cause Analysis\n                  process exists with communication paths for what the\n                  problem was, and how it was corrected or prevented.\n                  RCA correction is prioritized above feature releases\n                  for immediate implementation and deployment.\n                \n\n\n\n                  Plan for disaster recovery (DR)\n                \n Active-Active deployed across at least two regions. Infrastructure is fully\n                  scaled and statically stable across regions. Data is partitioned and synchronized\n                  across regions. Encrypted backups via RDS. Region failure is practiced in a game\n                  day, and is coordinated with AWS. During restoration a new database primary may\n                  need to be promoted.", "metadata": {"source": "https://docs.aws.amazon.com/wellarchitected/latest/reliability-pillar/s-99.999-or-higher-scenario-with-a-recovery-time-under-1-minute.html", "title": "5 9s (99.999%) or higher scenario with a recovery time under one minute - Reliability Pillar", "description": "This availability goal for applications requires almost no downtime or data loss for specific times. Applications that could have this availability goal include, for example certain banking, investing, finance, government, and critical business applications that are the core business of an extremely large-revenue generating business. The desire is to have strongly consistent data stores and complete redundancy at all layers. We have selected a SQL-based data store. However, in some scenarios, we will find it difficult to achieve a very small RPO. If you can partition your data, it\u2019s possible to have no data loss. This might require you to add application logic and latency to ensure that you have consistent data between geographic locations, as well as the capability to move or copy data between partitions. Performing this partitioning might be easier if you use a NoSQL database.", "language": "en-US"}}